
## This is a SAMPLE metadata file for a GitHub Action.  For more info:
##    https://help.github.com/en/articles/metadata-syntax-for-github-actions

name: pester-tests-report
author: EBekker
description: |
  Executes PowerShell Pester tests within a GitHub Workflow
  and produces a Tests Report.

## Here you describe your *formal* inputs -- those that are
## documented and can be displayed by the marketplace.
## You also use these to identify the *required* inputs.
inputs:

  shell:
    description: |
      Specifies whether pester should run in Powershell or Windows 
      PowerShell. Valid values are 'pwsh' (PowerShell) and 'powershell' 
      (Windows Powershell). Defaults to 'pwsh'. Note that the 'powershell' 
      option is only valid when run on Windows.
    required: false
    default: pwsh

  test_results_path:
    description: |
      Path to the test results file which will be used to generate
      a report.  If this path is provided, it will override the
      execution of all Pester tests, so the **`include_paths`**
      input and all other inputs that drive the test invocation behavior
      will be ignored. Instead a report will be generated based on the
      results stored in the file pointed to by this path.
      At this time, the only test results format supported is the
      NUnit 2.5 Tests results XML schema.
    required: false

  full_names_filters:
    description:
      Comma-separated list of test full names, or with `-like`
      wildcards, to restrict which tests are resolved.  The default
      is to include every test discovered matching the other input
      parameters.
    required: false

  include_paths:
    description: |
      Comma-separated list of one or more test files or directories
      that contain test files, relative to the root of the project.
      This path is optional and defaults to the project root,
      in which case all tests script across the entire project tree
      will be discovered.  A test script is identified by the
      filename pattern `*.Tests.ps1`.
      This parameter is _ignored_ if the **`test_results_path`**
      parameter is also provided.
    required: false

  exclude_paths:
    description: |
      Comma-separated list of one or more test files or directories
      that contain test files, relative to the root of the project,
      that will be excluded from the list fo auto-discovered tests.
      This parameter is _ignored_ if the **`test_results_path`**
      parameter is also provided.
    required: false

  include_tags:
    description: |
      Comma-separated list of tags to include for testing.
      This parameter is _ignored_ if the **`test_results_path`**
      parameter is also provided.
    required: false

  exclude_tags:
    description: |
      Comma-separated list of tags to exclude for testing.
      This parameter is _ignored_ if the **`test_results_path`**
      parameter is also provided.
    required: false

  output_level:
    description: |
      Optionally specify the level of output detail for the test results.
      May be one of: `none`, `Minimal`, `normal`, `detailed`, `diagnostic`
      The default is `normal`.
    required: false

  report_name:
    description: |
      The name of the report object that will be attached to the
      Workflow Run.  Defaults to the name `TEST_RESULTS_<datetime>`
      where `<datetime>` is in the form `yyyyMMdd_hhmmss`.

  report_title:
    description: |
      The title of the report that will be embedded in the report
      itself, which defaults to the same as the `report_name` input.

  github_token:
    description: |
      GITHUB_TOKEN to authenticate against API calls to attach
      report to Workflow Run.

  skip_check_run:
    description: |
      If true, will skip attaching the Tests Result report to
      the Workflow Run using a Check Run.  Useful if you just
      want to produce a Gist-based report via the `gist_name`
      and `gist_token` input parameters.

  gist_name:
    description: |
      If this value is specifed, the Test Results Report will be
      attached as a version of a Gist under the name of this input.
      The `gist_token` input is also required to use this feature.
  
  gist_badge_label:
    description: |
      If specified, the Test Report Gist will also include an adjacent
      badge rendered with the status of the associated Test Report and
      and label content of this input.  In addition to any static text
      you can provide _escape tokens_ of the form `%name%` where name
      can be the name of any field returned from a Pester Result, such
      as `ExecutedAt` or `Result`.  If you want a literal percent, just
      specify an empty name as in `%%`.
  
  gist_badge_message:
    description: |
      If Gist badge generation is enabled by providing a value for the
      `gist_badge_label` input, this input allows you to override the
      default message on the badge, which is equivalent to the the
      Pester Result `Status` such as `Failed` or `Passed`.  As with the
      label input, you can specify escape tokens in addition to literal
      text.  See the label input description for more details.

  gist_token:
    description: |
      GitHub OAuth/PAT token to be used for accessing Gist to store
      test results report. The integrated GITHUB_TOKEN that is normally
      accessible during a Workflow does not include read/write permissions
      to associated Gists, therefore a separate token is needed.
      You can control which account is used to actually store the state by
      generating a token associated with the target account.

  coverage_paths:
    description: |
      Comma-separated list of one or more directories to scan for code 
      coverage, relative to the root of the project. Will include all .ps1
      and .psm1 files under these directories recursively.
    required: false

  coverage_report_name:
    description: |
      The name of the code coverage report object that will be attached 
      to the Workflow Run.  Defaults to the name 
      `COVERAGE_RESULTS_<datetime>` where `<datetime>` is in the form 
      `yyyyMMdd_hhmmss`.
    required: false

  coverage_report_title:
    description: |
      The title of the code coverage report that will be embedded in the 
      report itself, which defaults to the same as the 
      `code_coverage_report_name` input.
    required: false

  coverage_gist:
    description: |
      If true, will attach the coverage results to the gist specified in 
      `gist_name`.
    required: false

  coverage_gist_badge_label:
    description: |
      If specified, the Test Report Gist will also include an adjacent
      badge rendered with the percentage of the associated Coverage Report 
      and label content of this input.
    required: false

  tests_fail_step:
    description: |
      If true, will cause the step to fail if one or more tests fails.
    required: false


## Here you describe your *formal* outputs.
outputs:

  test_results_path:
    description: |
      Path to the test results file.  If the same-named input
      was provided to this action, this value will be the same.
      Otherwise, this will be the path to where the test results
      file was generated from running the resolved Pester tests.
    value: ${{ steps.runaction.outputs.test_results_path }}
  
  error_message:
    description: |
      The summary message of the error returned by Pester, or
      empty if no error was produced.
    value: ${{ steps.runaction.outputs.error_message }}
  
  error_clixml_path:
    description:
      If Pester produced an error during invocation, this will
      be the path to an export of the full error record in the
      CLIXML form.  A subsequent PowerShell step can recover
      this object using the `Import-Clixml` cmdlet.
    value: ${{ steps.runaction.outputs.error_clixml_path }}
  
  result_clixml_path:
    description:
      If Pester produced an invocation result, this will
      be the path to an export of the full result record in the
      CLIXML form.  A subsequent PowerShell step can recover
      this object using the `Import-Clixml` cmdlet.
    value: ${{ steps.runaction.outputs.result_clixml_path }}

  result_value:
    description: |
      A single string indicating the final result such as
      `Failed` or `Passed`.
    value: ${{ steps.runaction.outputs.result_value }}
  
  total_count:
    description: Total number of tests discovered.
    value: ${{ steps.runaction.outputs.total_count }}

  passed_count:
    description: Total number of tests passed.
    value: ${{ steps.runaction.outputs.passed_count }}

  failed_count:
    description: Total number of tests failed.
    value: ${{ steps.runaction.outputs.failed_count }}

  coverage_results_path:
    description: |
      Path to the code coverage results file in JaCoCo XML format.
    value: ${{ steps.runaction.outputs.coverage_results_path }}


branding:
  color: purple
  icon: check-circle

runs:
  using: composite
  steps:
    - name: Run Action
      id: runaction
      run: . "$env:GITHUB_ACTION_PATH\action.ps1"
      shell: ${{ inputs.shell }}
      env:
        INPUT_TEST_RESULTS_PATH: ${{ inputs.test_results_path }}
        INPUT_FULL_NAMES_FILTERS: ${{ inputs.full_names_filters }}
        INPUT_INCLUDE_PATHS: ${{ inputs.include_paths }}
        INPUT_EXCLUDE_PATHS: ${{ inputs.exclude_paths }}
        INPUT_INCLUDE_TAGS: ${{ inputs.include_tags }}
        INPUT_EXCLUDE_TAGS: ${{ inputs.exclude_tags }}
        INPUT_OUTPUT_LEVEL: ${{ inputs.output_level }}
        INPUT_REPORT_NAME: ${{ inputs.report_name }}
        INPUT_REPORT_TITLE: ${{ inputs.report_title }}
        INPUT_GITHUB_TOKEN: ${{ inputs.github_token }}
        INPUT_SKIP_CHECK_RUN: ${{ inputs.skip_check_run }}
        INPUT_GIST_NAME: ${{ inputs.gist_name }}
        INPUT_GIST_BADGE_LABEL: ${{ inputs.gist_badge_label }}
        INPUT_GIST_BADGE_MESSAGE: ${{ inputs.gist_badge_message }}
        INPUT_GIST_TOKEN: ${{ inputs.gist_token }}
        INPUT_COVERAGE_PATHS: ${{ inputs.coverage_paths }}
        INPUT_COVERAGE_REPORT_NAME: ${{ inputs.coverage_report_name }}
        INPUT_COVERAGE_REPORT_TITLE: ${{ inputs.coverage_report_title }}
        INPUT_COVERAGE_GIST: ${{ inputs.coverage_gist }}
        INPUT_COVERAGE_GIST_BADGE_LABEL: ${{ inputs.coverage_gist_badge_label }}
        INPUT_TESTS_FAIL_STEP: ${{ inputs.tests_fail_step }}

